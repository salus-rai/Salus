<!DOCTYPE html>
<html><head></head><body><div class="main-panel wiki-content">
<div class="description">
<div class="header-wrapper" style="max-width: initial">
<!-- breadcrumbs could be implemented and inserted here -->
<div></div>

</div>
<div class="header-wrapper">
<div class="title-wrapper">
<div class="title">
<h1 style="display: flex; align-items: center;">
                                        Hallucinations
                                    </h1>
</div>
<div class="row" style="display: flex;padding: 0; ">

</div>
</div>
</div>
<div class="content-wrapper">
<style>@media (prefers-color-scheme: dark) { }</style>
<div class="contentLayout2">
<style>[data-colorid=xj27c5q2if]{color:#0747a6} html[data-color-mode=dark] [data-colorid=xj27c5q2if]{color:#5999f8}[data-colorid=emycwuora0]{color:#0747a6} html[data-color-mode=dark] [data-colorid=emycwuora0]{color:#5999f8}[data-colorid=s9pb8vuwbh]{color:#0747a6} html[data-color-mode=dark] [data-colorid=s9pb8vuwbh]{color:#5999f8}[data-colorid=snrgamhfyz]{color:#0747a6} html[data-color-mode=dark] [data-colorid=snrgamhfyz]{color:#5999f8}[data-colorid=n9wzpvkt9i]{color:#0747a6} html[data-color-mode=dark] [data-colorid=n9wzpvkt9i]{color:#5999f8}[data-colorid=u6mtikjxpy]{color:#0747a6} html[data-color-mode=dark] [data-colorid=u6mtikjxpy]{color:#5999f8}[data-colorid=gk3uhiz7tu]{color:#0747a6} html[data-color-mode=dark] [data-colorid=gk3uhiz7tu]{color:#5999f8}[data-colorid=k447yqspw0]{color:#0747a6} html[data-color-mode=dark] [data-colorid=k447yqspw0]{color:#5999f8}[data-colorid=xcbcwswoem]{color:#0747a6} html[data-color-mode=dark] [data-colorid=xcbcwswoem]{color:#5999f8}</style>
<div class="columnLayout fixed-width default" data-layout="fixed-width">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<div class="toc-macro client-side-toc-macro conf-macro output-block" data-cssliststyle="none" data-hasbody="false" data-headerelements="H1,H2" data-layout="default" data-local-id="4a8d2e9f-0d51-4885-a348-193dd9311c47" data-macro-id="64760874-aa82-4414-9d0d-54d6b68dcec7" data-macro-name="toc" data-numberedoutline="false" data-structure="list">
<ul>
<li><a class="not-blank" href="#Introduction"><span data-colorid="gk3uhiz7tu">Introduction</span></a></li>
<li><a class="not-blank" href="#FocusAreas"><span data-colorid="k447yqspw0">Focus Areas</span></a></li>
<li><a class="not-blank" href="#SolutionandBenefits"><span data-colorid="xcbcwswoem">Solution and Benefits</span></a></li>




<li><a class="not-blank" href="#InfosysResponsibleAItoolkitHallucination"><span data-colorid="n9wzpvkt9i">Infosys Responsible AI toolkit - Hallucination</span></a></li>
<li><a class="not-blank" href="#MethodstoIdentifyHallucinationsinRAIToolkit"><span data-colorid="u6mtikjxpy">Methods to Identify Hallucinations in RAI Toolkit</span></a></li>
<li><a class="not-blank" href="#MultimodalRAG">Multi-modal RAG</a></li>

</ul>
</div>
<h2 id="Introduction"><span data-colorid="gk3uhiz7tu">Introduction</span><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h2>
<p>Hallucinations in LLMs occur when the model's internal biases, learned patterns, or overgeneralizations lead to the creation of text that is not consistent with factual information. This can happen when the model struggles to distinguish between real and imagined information.</p>
<p>To address hallucinations in LLMs, it is essential to detect, quantify, and mitigate them. The Infosys Responsible AI toolkit offers features to achieve this. By employing techniques such as Chain of Thought, Thread of Thought, and Graph of Thought, potential hallucinations in diverse LLM outputs can be identified. Internet searches aid in verifying the accuracy of responses. G Eval metrics like adherence, faithfulness, and correctness assess the degree of hallucinations in both original and refined LLM outputs.</p>
<h2 id="FocusAreas"><span data-colorid="k447yqspw0">Focus Areas</span><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h2>
</div>
</div>
</div>
<div class="columnLayout three-equal default" data-layout="three-equal">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p><span data-colorid="snrgamhfyz">Unstructured Text</span></p>
<ul>
<li><p>Enables the detection of hallucinations in LLM responses generated from multiple external sources, including PDF, text, and DOC files. </p></li>
<li><p>Provides citation of the generated response from which information was retrieved. </p></li>
<li><p>Utilizes diversified output explainability techniques (CoT, ToT) to identify hallucinations.</p></li>
<li><p>Quantifies the severity of hallucinations using metrics like correctness, faithfulness, adherence and relevance.</p></li>
</ul>
</div>
</div>
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p><span data-colorid="emycwuora0">Image </span></p>
<ul>
<li><p>Enables the Hallucination detection in the information retrieval from multiple external sources including JPG, JPEG, JFIF.</p></li>
</ul>
<p> </p>
</div>
</div>
<div class="cell normal" data-type="normal">
<div class="innerCell">
<p><span data-colorid="xj27c5q2if">Video </span></p>
<ul>
<li><p>Enables the Hallucination detection in the information retrieval from multiple external sources including mkv and mp4.</p></li>
</ul>
</div>
</div>
</div>
<div class="columnLayout fixed-width default" data-layout="fixed-width">
<div class="cell normal" data-type="normal">
<div class="innerCell">
<h2 id="SolutionandBenefits"><span data-colorid="xcbcwswoem">Solution and Benefits</span><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h2><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size" style="max-width: 760px;"><img alt="image-20241009-024330.png" class="confluence-embedded-image image-center cursor-pointer" data-height="520" data-linked-resource-container-id="308019381" data-linked-resource-container-version="74" data-linked-resource-content-type="image/png" data-linked-resource-default-alias="image-20241009-024330.png" data-linked-resource-id="1057587692" data-linked-resource-type="attachment" data-linked-resource-version="1" data-media-id="cbf3d336-b20d-4358-9661-99f20f051a01" data-media-type="file" data-thumbnail-url="/content/58f1bf1b-24d0-4a88-8e47-edf6a46686f0/207815356/228720962/308019381/media/US1xemYyZHJEa0lsdmQ5V2lHQ3psOFA3OGY4Y1N3Zkphem5LMk1jQXFMTT0=.TlRobU1XSm1NV0l0TWpSa01DMDBZVGc0TFRobE5EY3RaV1JtTm1FME5qWTRObVl3Lk1UY3pPVGswTmpNMU5EQTROUT09LmJ3PT0uZEdoMWJXSnVZV2xzY3c9PS5NekE0TURFNU16Z3guYVcxaFoyVXRNakF5TkRFd01Ea3RNREkwTXpNd0xuQnVadz09LmRtVnljMmx2YmoweEptMXZaR2xtYVdOaGRHbHZia1JoZEdVOU1UY3lPRFEwTVRneE1qYzJOQ1pqWVdOb1pWWmxjbk5wYjI0OU1TWmhjR2s5ZGpJbWQybGtkR2c5TnpBeUptaGxhV2RvZEQwek9UTT0=/image-20241009-024330.png" data-unresolved-comment-count="0" data-width="927" loading="lazy" name="image-attachment" src="github-pages/images/image-20241009-024330.png" style="width: 702px;" width="702"/></span>
<p><span class="confluence-embedded-file-wrapper conf-macro output-inline" data-hasbody="false" data-macro-id="2c756e03-b7fc-43d3-9f1f-8df6f29a125b" data-macro-name="view-file"><a class="confluence-embedded-file" data-file-src="/wiki/download/attachments/308019381/Hallucination_RAI.pptx?version=1&amp;modificationDate=1725943278958&amp;cacheVersion=1&amp;api=v2" data-has-thumbnail="true" data-linked-resource-container-id="308019381" data-linked-resource-default-alias="Hallucination_RAI.pptx" data-linked-resource-id="985269069" data-linked-resource-type="attachment" data-linked-resource-version="1" data-media-id="0f5e3d2e-da7b-4a6e-ab36-7a4ad166b01c" data-media-type="file" data-mime-type="application/vnd.openxmlformats-officedocument.presentationml.presentation" data-nice-type="Microsoft PowerPoint Presentation" download="" href="/content/58f1bf1b-24d0-4a88-8e47-edf6a46686f0/207815356/228720962/308019381/media/QWxGeFpWUGhNdGJkSnlBdW1lSXhGOEpvZzFseWlSTlZlejJ6cmpGbkR2Yz0=.TlRobU1XSm1NV0l0TWpSa01DMDBZVGc0TFRobE5EY3RaV1JtTm1FME5qWTRObVl3Lk1UY3pPVGswTmpNMU5EQTRPQT09LmJ3PT0uWVhSMFlXTm9iV1Z1ZEhNPS5NekE0TURFNU16Z3guU0dGc2JIVmphVzVoZEdsdmJsOVNRVWt1Y0hCMGVBPT0uZG1WeWMybHZiajB4Sm0xdlpHbG1hV05oZEdsdmJrUmhkR1U5TVRjeU5UazBNekkzT0RrMU9DWmpZV05vWlZabGNuTnBiMjQ5TVNaaGNHazlkakk9/Hallucination_RAI.pptx" target="_blank"><img height="250" src="github-pages/images/Hallucination_RAI.pptx"/></a></span> </p>






















<h2 id="InfosysResponsibleAItoolkitHallucination"><span data-colorid="n9wzpvkt9i">Infosys Responsible AI toolkit - Hallucination</span><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h2>
<div class="expand-container conf-macro output-block" data-hasbody="true" data-macro-id="c28b7277-06fe-465e-bb5d-6472f2ba7399" data-macro-name="expand" id="expander-1109345851">
<div class="expand-control" id="expander-control-1109345851" onclick="expandContent('expander-content-1109345851', 'expander-control-1109345851')">
<span class="expand-control-icon icon"> </span><span class="expand-control-text">Using Hallucination tenet of Infosys Responsible AI toolkit</span>
</div>
<div class="expand-content expand-hidden" id="expander-content-1109345851">
<h5 id="Howto">How to?<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h5>
<p>Login to: <a class="external-link" href="" rel="nofollow" target="_blank">RAI Portal</a></p>
<ol start="1">
<li><p>Navigate to: Generative AI (toggle button) </p></li>
<li><p>FM-Moderation (check box) → <strong>File Upload</strong> (toggle button) → Upload file </p></li>
</ol><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size" style="max-width: 760px;"><img alt="image-20241010-043834.png" class="confluence-embedded-image image-center cursor-pointer" data-height="645" data-linked-resource-container-id="308019381" data-linked-resource-container-version="74" data-linked-resource-content-type="image/png" data-linked-resource-default-alias="image-20241010-043834.png" data-linked-resource-id="1060143105" data-linked-resource-type="attachment" data-linked-resource-version="1" data-media-id="be52933a-e973-47d1-a946-fc979ddd9c92" data-media-type="file" data-thumbnail-url="/content/58f1bf1b-24d0-4a88-8e47-edf6a46686f0/207815356/228720962/308019381/media/bzAyamlfa3VSa2tFTld6OV9kMkJaMFYxaExCN3NBMlk4eGxGVzBhakl5UT0=.TlRobU1XSm1NV0l0TWpSa01DMDBZVGc0TFRobE5EY3RaV1JtTm1FME5qWTRObVl3Lk1UY3pPVGswTmpNMU5EQTROdz09LmJ3PT0uZEdoMWJXSnVZV2xzY3c9PS5NekE0TURFNU16Z3guYVcxaFoyVXRNakF5TkRFd01UQXRNRFF6T0RNMExuQnVadz09LmRtVnljMmx2YmoweEptMXZaR2xtYVdOaGRHbHZia1JoZEdVOU1UY3lPRFV6TlRFeE56TXlNQ1pqWVdOb1pWWmxjbk5wYjI0OU1TWmhjR2s5ZGpJbWQybGtkR2c5TnpNeEptaGxhV2RvZEQwek1qaz0=/image-20241010-043834.png" data-unresolved-comment-count="0" data-width="1432" loading="lazy" name="image-attachment" src="github-pages/images/image-20241010-043834.png" style="width: 731px;" width="731"/></span>
<ol start="3">
<li><p>Enter the required <strong>prompt</strong></p></li>
<li><p>Under <strong>Faithfulness Check,</strong> Populates LLM response curated by Hallucination score, source document detail (name), and evaluation metrics</p></li>
<li><p><strong>Evaluation Metrics</strong> Value Ranges from 1 to 5.<br/><strong>Faithfulness:</strong> Measures how well LLM's response captures the content and intent of the prompt and document<br/><strong>Relevance:</strong> Measures how closely the LLM's response relates to the document uploaded<br/><strong>Adherence:</strong> Measures how well the LLM's response follows guidelines, limitations, or specific instructions in the prompt<br/><strong>Correctness:</strong> Measures the LLM's response for factual inaccuracy, completeness, clarity, and neutrality of the sentences of the response. <strong>Evaluation Reasoning</strong> is Explanation on metric values<br/></p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size" style="max-width: 760px;"><img alt="image-20241010-051153.png" class="confluence-embedded-image image-center cursor-pointer" data-height="671" data-linked-resource-container-id="308019381" data-linked-resource-container-version="74" data-linked-resource-content-type="image/png" data-linked-resource-default-alias="image-20241010-051153.png" data-linked-resource-id="1060143507" data-linked-resource-type="attachment" data-linked-resource-version="1" data-media-id="8966c57a-8297-4817-a80a-bacea4d2cbd5" data-media-type="file" data-thumbnail-url="/content/58f1bf1b-24d0-4a88-8e47-edf6a46686f0/207815356/228720962/308019381/media/VGtrQjUtdElhc2hfdjFvMXNqdlBhZFRFd1ZfRk1lRHRnT0F5MFFNR0UwST0=.TlRobU1XSm1NV0l0TWpSa01DMDBZVGc0TFRobE5EY3RaV1JtTm1FME5qWTRObVl3Lk1UY3pPVGswTmpNMU5EQTROdz09LmJ3PT0uZEdoMWJXSnVZV2xzY3c9PS5NekE0TURFNU16Z3guYVcxaFoyVXRNakF5TkRFd01UQXRNRFV4TVRVekxuQnVadz09LmRtVnljMmx2YmoweEptMXZaR2xtYVdOaGRHbHZia1JoZEdVOU1UY3lPRFV6TnpFeE5qVXhOQ1pqWVdOb1pWWmxjbk5wYjI0OU1TWmhjR2s5ZGpJbWQybGtkR2c5TnpBM0ptaGxhV2RvZEQwek16RT0=/image-20241010-051153.png" data-unresolved-comment-count="0" data-width="1431" loading="lazy" name="image-attachment" src="github-pages/images/image-20241010-051153.png" style="width: 707px;" width="707"/></span><p> </p></li>
<li><p>Switch to <strong>Factual Check</strong> tab</p></li>
<li><p>Reasoning by Thread of thoughts</p></li>
<li><p>Verification of LLM response by Chain of Verifications</p></li>
<li><p>Additional Explanation button to display explanation through Chain of Thoughts and Token Importance charts </p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size" style="max-width: 760px;"><img alt="image-20241010-052714.png" class="confluence-embedded-image image-center cursor-pointer" data-height="508" data-linked-resource-container-id="308019381" data-linked-resource-container-version="74" data-linked-resource-content-type="image/png" data-linked-resource-default-alias="image-20241010-052714.png" data-linked-resource-id="1060111079" data-linked-resource-type="attachment" data-linked-resource-version="1" data-media-id="017a0b1b-460d-4e17-930e-9e0628db7d7f" data-media-type="file" data-thumbnail-url="/content/58f1bf1b-24d0-4a88-8e47-edf6a46686f0/207815356/228720962/308019381/media/blItdk41X090dm5DdTBJY0N6bzZDeWpsQjQzekJubDNsZUxWNE5CMXpKaz0=.TlRobU1XSm1NV0l0TWpSa01DMDBZVGc0TFRobE5EY3RaV1JtTm1FME5qWTRObVl3Lk1UY3pPVGswTmpNMU5EQTROdz09LmJ3PT0uZEdoMWJXSnVZV2xzY3c9PS5NekE0TURFNU16Z3guYVcxaFoyVXRNakF5TkRFd01UQXRNRFV5TnpFMExuQnVadz09LmRtVnljMmx2YmoweEptMXZaR2xtYVdOaGRHbHZia1JoZEdVOU1UY3lPRFV6T0RBek56SXpOaVpqWVdOb1pWWmxjbk5wYjI0OU1TWmhjR2s5ZGpJbWQybGtkR2c5TnpBM0ptaGxhV2RvZEQweU9URT0=/image-20241010-052714.png" data-unresolved-comment-count="0" data-width="1234" loading="lazy" name="image-attachment" src="github-pages/images/image-20241010-052714.png" style="width: 707px;" width="707"/></span></li>
<li><p>Displays matrix with top 10 tokens and their importance</p></li>
<li><p>The Token Importance Distribution Chart illustrates the significance of individual tokens by displaying the distribution of their associated impact scores. The chart's shape reveals the following insights:</p>
<ul>
<li><p>Flat Distribution:<strong> </strong>Tokens have similar importance, with no clear standout</p></li>
<li><p>Left-Peaked Distribution: Tokens have low impact scores, indicating lesser importance</p></li>
<li><p>Right-Peaked Distribution: Tokens have high impact scores, signifying greater importance</p></li>
</ul></li>
<li><p>Displays importance of each token (considered top 10 tokens based on their importance for this chart)</p></li>
</ol>
</div>
</div>
<p> </p>
<h2 id="MethodstoIdentifyHallucinationsinRAIToolkit"><span data-colorid="u6mtikjxpy">Methods to Identify Hallucinations in RAI Toolkit</span><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h2>
<h3 id="ThreadofThoughtsThoT"><strong>Thread of Thoughts (ThoT)</strong><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>Thread of Thoughts (ThoT) is developed to address challenges in chaotic contexts, where LLMs struggle to sift through and prioritize relevant information amidst a plethora of data.</p>
<p>This is a novel prompting technique designed to enhance the reasoning capabilities of Large Language Models (LLMs) in handling chaotic contexts. The approach involves systematic segmentation, summarization, and analysis, which aligns with human cognitive patterns. It draws inspiration from human cognitive processes and aims to systematically segment and analyze extended contexts for better comprehension and accuracy.</p>
<h4 id="Whyisitneeded1"><strong>Why is it needed?</strong><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>Thread of Thoughts (ThoT) is designed for chaotic contexts, while Chain of Thoughts (CoT) follows a linear reasoning process suitable for structured contexts. The key advantage is its ability to segment and analyze chaotic contexts, enhancing information extraction and reasoning contexts where information is complex and disorganized. It skillfully breaks down and analyzes extensive contexts while selectively choosing relevant information.</p><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size" style="max-width: 760px;"><img alt="image-20240522-095203.png" class="confluence-embedded-image image-center cursor-pointer" data-height="131" data-linked-resource-container-id="308019381" data-linked-resource-container-version="74" data-linked-resource-content-type="image/png" data-linked-resource-default-alias="image-20240522-095203.png" data-linked-resource-id="755204251" data-linked-resource-type="attachment" data-linked-resource-version="1" data-media-id="40001daf-02e5-44e2-89d1-37814e0ae141" data-media-type="file" data-thumbnail-url="/content/58f1bf1b-24d0-4a88-8e47-edf6a46686f0/207815356/228720962/308019381/media/d3pzTWlTV3pyY21FZmVsWVJBYWVnSFFSbHdKTzduLTFibjhka1JGcGlSTT0=.TlRobU1XSm1NV0l0TWpSa01DMDBZVGc0TFRobE5EY3RaV1JtTm1FME5qWTRObVl3Lk1UY3pPVGswTmpNMU5EQTROdz09LmJ3PT0uZEdoMWJXSnVZV2xzY3c9PS5NekE0TURFNU16Z3guYVcxaFoyVXRNakF5TkRBMU1qSXRNRGsxTWpBekxuQnVadz09LmRtVnljMmx2YmoweEptMXZaR2xtYVdOaGRHbHZia1JoZEdVOU1UY3hOak0zTVRVeU56RTBNU1pqWVdOb1pWWmxjbk5wYjI0OU1TWmhjR2s5ZGpJbWQybGtkR2c5TnpJMEptaGxhV2RvZEQweU1EST0=/image-20240522-095203.png" data-unresolved-comment-count="0" data-width="468" loading="lazy" name="image-attachment" src="github-pages/images/image-20240522-095203.png" style="width: 724px;" width="724"/></span>
<h4 id="HowitdiffersfromChainofThoughtCoT"><strong>How it differs from Chain of Thought (CoT)?</strong><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4><span class="confluence-embedded-file-wrapper image-left-wrapper confluence-embedded-manual-size" style="max-width: 760px;"><img alt="image-20240531-011152.png" class="confluence-embedded-image image-left cursor-pointer" data-height="393" data-linked-resource-container-id="308019381" data-linked-resource-container-version="74" data-linked-resource-content-type="image/png" data-linked-resource-default-alias="image-20240531-011152.png" data-linked-resource-id="773652503" data-linked-resource-type="attachment" data-linked-resource-version="1" data-media-id="2e8a71d2-886e-4f4b-99c1-2351302222fd" data-media-type="file" data-thumbnail-url="/content/58f1bf1b-24d0-4a88-8e47-edf6a46686f0/207815356/228720962/308019381/media/MVhtX1Naek9NRFNqY0FiaTBsbER1REdrTTg0R05nM0RldTVJYlpHX2lHND0=.TlRobU1XSm1NV0l0TWpSa01DMDBZVGc0TFRobE5EY3RaV1JtTm1FME5qWTRObVl3Lk1UY3pPVGswTmpNMU5EQTRPQT09LmJ3PT0uZEdoMWJXSnVZV2xzY3c9PS5NekE0TURFNU16Z3guYVcxaFoyVXRNakF5TkRBMU16RXRNREV4TVRVeUxuQnVadz09LmRtVnljMmx2YmoweEptMXZaR2xtYVdOaGRHbHZia1JoZEdVOU1UY3hOekV4TnpreE5UUXpNeVpqWVdOb1pWWmxjbk5wYjI0OU1TWmhjR2s5ZGpJbWQybGtkR2c5TnpBeUptaGxhV2RvZEQwME1EWT0=/image-20240531-011152.png" data-unresolved-comment-count="0" data-width="679" loading="lazy" name="image-attachment" src="github-pages/images/image-20240531-011152.png" style="width: 702px;" width="702"/></span><span class="confluence-embedded-file-wrapper image-left-wrapper confluence-embedded-manual-size" style="max-width: 760px;"><img alt="image-20240522-095625.png" class="confluence-embedded-image image-left cursor-pointer" data-height="648" data-linked-resource-container-id="308019381" data-linked-resource-container-version="74" data-linked-resource-content-type="image/png" data-linked-resource-default-alias="image-20240522-095625.png" data-linked-resource-id="755236940" data-linked-resource-type="attachment" data-linked-resource-version="1" data-media-id="4fa7a35f-d46e-432e-8604-68d14bccdcb4" data-media-type="file" data-thumbnail-url="/content/58f1bf1b-24d0-4a88-8e47-edf6a46686f0/207815356/228720962/308019381/media/eDU2YndSRUVSdUJsQkxFSkJHZlRkVDNmWmRtaW8wNmNFTUZ4dmJiNjJPRT0=.TlRobU1XSm1NV0l0TWpSa01DMDBZVGc0TFRobE5EY3RaV1JtTm1FME5qWTRObVl3Lk1UY3pPVGswTmpNMU5EQTRPQT09LmJ3PT0uZEdoMWJXSnVZV2xzY3c9PS5NekE0TURFNU16Z3guYVcxaFoyVXRNakF5TkRBMU1qSXRNRGsxTmpJMUxuQnVadz09LmRtVnljMmx2YmoweEptMXZaR2xtYVdOaGRHbHZia1JoZEdVOU1UY3hOak0zTVRjNE9EVTVNaVpqWVdOb1pWWmxjbk5wYjI0OU1TWmhjR2s5ZGpJbWQybGtkR2c5TkRZekptaGxhV2RvZEQwMk5EZz0=/image-20240522-095625.png" data-unresolved-comment-count="0" data-width="463" loading="lazy" name="image-attachment" src="github-pages/images/image-20240522-095625.png" style="width: 463px" width="463"/></span>
<h4 id="Usage"><strong>Usage:</strong><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>Ideal for scenarios with mixed, non-sequential, or complex information structures.</p>
<p>Reference Research Paper: <a class="external-link" href="https://arxiv.org/pdf/2311.08734v1" rel="nofollow" target="_blank">2311.08734v1 (arxiv.org)</a></p>
<h3 id="GEvalMetrics">G- Eval Metrics<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>The G-eval metrics are tools used to evaluate the performance and quality of texts generated by LLMs, taking into account the many specific nuances of these models. The G-Eval metrics leverage existing AI models and evaluate metrics like relevance, adherence, correctness, and faithfulness to assess the response generated by the LLM. </p>
<h4 id="1Correctness">1. Correctness <a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>The correctness metric assesses how accurately a generated output aligns with the intended meaning or ground truth. In the context of hallucination, it evaluates whether the generated content contains factual inaccuracies or fabrications.</p>
<p>For example, if a language model generates a sentence claiming that “dogs can fly,” a correctness metric would flag this as an incorrect statement.</p>
<h4 id="2Adherence">2. Adherence<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>The adherence metric measures how well the generated content adheres to specific guidelines, constraints, or stylistic rules. In the context of hallucination, it evaluates whether the generated text adheres to the expected patterns or norms.</p>
<p>For instance, if a chatbot generates a response that violates grammatical rules or deviates from the desired tone, an adherence metric would detect this inconsistency.</p>
<h4 id="3Relevance">3. Relevance<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>The relevance metric gauges how closely the generated output aligns with the given context or prompt. It assesses whether the content is contextually appropriate and relevant. In hallucination scenarios, relevance metrics help identify instances where the generated text diverges significantly from the context or introduces unrelated information.</p>
<h4 id="4Faithfulness">4. Faithfulness<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>The faithfulness metric evaluates the extent to which the generated content faithfully represents the input or source material. It measures whether the model adheres to the original intent, facts, or details. In the context of hallucination, a faithfulness metric would highlight instances where the model invents information or introduces content does not present in the input.</p>
<h3 id="ChainofVerificationCoVe">Chain of Verification (CoVe)<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>This measure is implemented directly to counteract hallucinations. As a reminder, hallucinations occur when the LLM responds incorrectly but in a logically coherent manner to a prompt.</p>
<p>The Chain of Verification aims to verify the coherence of different reasoning steps of the LLM.</p>
<p>It consists of 4 steps :</p>
<ol start="1">
<li><p><strong>Initial Response:</strong> The LLM provides an initial response to the prompt.</p></li>
<li><p><strong>Generation of Verifications:</strong> A set of verification questions is generated to check the initial response. Each question is designed to examine different aspects of the reasoning.</p></li>
<li><p><strong>Verification:</strong> Each verification question is answered independently by the LLM.</p></li>
<li><p><strong>Final Response:</strong> Based on the answers to the verification questions, a revised response is generated.</p></li>
</ol><span class="confluence-embedded-file-wrapper image-center-wrapper confluence-embedded-manual-size" style="max-width: 760px;"><img alt="image-20240723-140756.png" class="confluence-embedded-image image-center cursor-pointer" data-height="221" data-linked-resource-container-id="308019381" data-linked-resource-container-version="74" data-linked-resource-content-type="image/png" data-linked-resource-default-alias="image-20240723-140756.png" data-linked-resource-id="886964281" data-linked-resource-type="attachment" data-linked-resource-version="1" data-media-id="d51f181f-9b63-4f02-aa99-b55154bf0bbd" data-media-type="file" data-thumbnail-url="/content/58f1bf1b-24d0-4a88-8e47-edf6a46686f0/207815356/228720962/308019381/media/M3I1b1o5YkNaVTUzX3FmalNNYWhfYUpoaWNVeEFIVFQ2QVg3SkVkdXBoMD0=.TlRobU1XSm1NV0l0TWpSa01DMDBZVGc0TFRobE5EY3RaV1JtTm1FME5qWTRObVl3Lk1UY3pPVGswTmpNMU5EQTRPQT09LmJ3PT0uZEdoMWJXSnVZV2xzY3c9PS5NekE0TURFNU16Z3guYVcxaFoyVXRNakF5TkRBM01qTXRNVFF3TnpVMkxuQnVadz09LmRtVnljMmx2YmoweEptMXZaR2xtYVdOaGRHbHZia1JoZEdVOU1UY3lNVGMwTXpZNE5EUTRPQ1pqWVdOb1pWWmxjbk5wYjI0OU1TWmhjR2s5ZGpJbWQybGtkR2c5TlRjeUptaGxhV2RvZEQweU9Uaz0=/image-20240723-140756.png" data-unresolved-comment-count="0" data-width="422" loading="lazy" name="image-attachment" src="github-pages/images/image-20240723-140756.png" style="width: 572px;" width="572"/></span>
<h3 id="ChainofThoughtsCoT">Chain of Thoughts (CoT)<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>CoT refers to a structured approach in problem-solving, where complex tasks are broken down into a sequence of logical steps. It mirrors human reasoning by constructing a coherent argument from premises to a conclusion. In artificial intelligence, CoT prompting involves systematically reasoning through a problem rather than providing context-based responses. It enhances problem-solving capabilities.</p>
<p>CoT can be relevant to understanding hallucinations. CoT can help break down the phenomenon, considering factors like neural processes, sensory input, and cognitive biases. CoT ensures that AI-generated responses maintain coherence, avoiding hallucinatory or nonsensical outputs.</p>
<h2 id="MultimodalRAG">Multi-modal RAG<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h2>
<h3 id="ImageInformationRetrievalRAG"><strong>Image Information Retrieval RAG</strong><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>Image Retrieval RAG (Retrieval Augmented Generation) is an advanced AI-based technology that enhances the capabilities of Responsible AI by incorporating multimodal inputs. It not only processes text inputs but also analyzes images, providing a more comprehensive and context-aware response.</p>
<h4 id="Whyisitneeded2"><strong>Why is it needed?</strong> <a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>For instance, in customer service, users can upload images along with their queries, enabling the AI to provide more accurate solutions based on both the image and the text context. This could be particularly valuable for businesses in the tech, furniture, fashion, or any other visual-centric industry. In marketing and advertising, this technology can be used to understand customer preferences better and deliver personalized suggestions and content. By analyzing the images users interact with or upload, businesses can gain insights into their tastes and behaviors, leading to more effective marketing strategies.</p>
<h4 id="Applications1">Applications:<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p> To find the similar products and acts as visual search, Categorization of Image in Inventory Management, Quality control for identifying the defects, Trend and design analysis in Fashion &amp; Design.</p>
<h3 id="VideoAudioInformationRetrievalRAG">Video (&amp;Audio) Information Retrieval RAG: <a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h3>
<p>Video Retrieval using Retrieval-Augmented Generation (RAG) is an advanced approach that combines traditional video retrieval methods with generative AI techniques. This integration aims to improve how users search for, retrieve, and interact with video content.</p>
<h4 id="Whyisitneeded3"><strong>Why is it needed? </strong><a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>Video retrieval is essential due to the increasing volume of content generated across platforms, making it crucial for users to find relevant videos quickly and effectively. In educational settings, it supports interactive learning by enabling access to specific examples, while also facilitating content discovery for users who may not know exactly what they want. Additionally, it aids researchers and professionals in accessing archived footage and enhances personalization through tailored recommendations. Effective video retrieval also promotes accessibility for individuals with disabilities and is vital for organizations in managing and utilizing their extensive video libraries efficiently.</p>
<h4 id="Applications2">Applications:<a aria-label-top="Copy link to heading" class="anchor-copy-link anchor-tooltip" target="_blank"></a></h4>
<p>Video Summarization, Interactive Q&amp;A.</p>









<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
<p> </p>
</div>
</div>
</div>
</div>
</div>
<!-- ATTACHMENTS -->

<script>
            document.addEventListener("DOMContentLoaded", () => {
                const wrapper = document.getElementById("attachments-wrapper");
                const button = document.getElementById("toggle-attachments-view-button");
                document.querySelectorAll(".file-full").forEach(el => {
                    el.addEventListener("mouseover", moveTooltip);
                });

                button.addEventListener("click", () => {
                    wrapper.classList.toggle("attachments-wrapper-gallery");
                    wrapper.classList.toggle("attachments-wrapper-list");
                });
            });

            function moveTooltip(e) {
                if (e.target.classList.contains("file-wrapper")) {
                    let docWidth = document.body.clientWidth;
                    let docHeight = document.body.clientHeight;
                    let rect = e.target.getBoundingClientRect();
                    let fileTooltip = e.target.parentElement.querySelector(".file-tooltip")
                    if (fileTooltip) {
                        if (rect.left <= docWidth / 2) {
                            fileTooltip.classList.add("left");
                            fileTooltip.classList.remove("right");
                        } else {
                            fileTooltip.classList.remove("left");
                            fileTooltip.classList.add("right");
                        }
                        if (rect.top <= docHeight / 2) {
                            fileTooltip.classList.add("top");
                            fileTooltip.classList.remove("bottom");
                        } else {
                            fileTooltip.classList.remove("top");
                            fileTooltip.classList.add("bottom");
                        }
                    }
                }
            }

        </script>
<script>
                hideGroup('attachments');
            </script>
<div id="footer-comments-outlet">
<div>
<div class="page-comment-wrapper" data-testid="page-comment-wrapper">
<div class="cc-q82yp6">
<div class="_1e0c1txw _i0dl1osq _otyru2gc">
<div class="_bfhklbf8 _1bsbzwfg _4t3izwfg _2rko1ssb _19pk1b66 _2hwxutpp"></div>
<div class="_1e0c11p5 _yv0ehpgh _727q19bv _bfhk1j28 _1bsbdgin _18u0u2gc">
<div class="_nd5lzmlf _bfhklbf8 _y3gn1h6o _1yt45uws _19itglyw _2rko1l7b"></div>
<div class="_nd5lbahz _bfhklbf8 _y3gn1h6o _1yt41h4g _19itglyw _2rko1l7b"></div>
</div>
</div>
<div class="_1sb2f705 _1e0c1ule _otyrpxbi _ca0qutpp _n7zl1l7n _1bsb1osq"></div>
<div class="_1e0c1txw _1n261g80" data-testid="comment-container">
<div class="_1e0c1txw _i0dl1osq _otyru2gc">
<div class="_bfhklbf8 _1bsbzwfg _4t3izwfg _2rko1ssb _19pk1b66 _2hwxutpp"></div>
<div class="_1bsb1osq _19itglyw _2rko1l7b _4t3i1ylp _syaz9s69 _ca0qze3t _1e0c1o8l _s7n4jp4b _18u0u2gc _16jlkb7n _bfhklbf8"></div>
</div>
</div>
</div>
</div>
</div>
</div>
<div id="inline-comments-outlet"></div>
</div>
</div></body><br/><br/></html>